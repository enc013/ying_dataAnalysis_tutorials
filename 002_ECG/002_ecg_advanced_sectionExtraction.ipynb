{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e3b40-23ff-42c5-9f81-ad7ff1e789d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import copy\n",
    "import heartpy as hp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyxdf\n",
    "import systole\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a6a16e-cf78-4493-9d9f-9d7f46a627dd",
   "metadata": {},
   "source": [
    "# __Event Markers__\n",
    "\n",
    "What are event markers!? \n",
    "\n",
    "They mark events but what is the significance of this. We can use event markers to mark when the experiment starts if we started the LSL recording before the actual experiment. You can also use event markers to mark when a part of the experiment ends. This way, we can __extract sections__ of the data and analyze them separately (rather than analyze the whole dataset where we waste time processing data that we won't look at). These unwanted sections may also have a lot of noise as the experiment transitions from different parts. \n",
    "\n",
    "However, event markers are only informative as the author of the code made them out to be. Sometimes, we may come across event markers that aren't informative at all (e.g. identical markers to mark the start of multiple experimental parts). Different parts of an experiment should be marked by unique events. However, repetitive markers are also useful. For instance, for an oddball experiment, repetitive stimuli is presented (audio or visual) that is interrupted by a deviant stimuli. For EEG, we can analyze event related potentials (ERPs) by using repetitive event markers, allowing us to mass extract these events. Sometimes, we may have missing event markers and may need to add our own events. \n",
    "\n",
    "# __Experimental Paradigm__\n",
    "\n",
    "We will analyze the VR-CCT data where we record ECG (Channel 66 and 67 in the EEG stream) and EEG data from subjects meditating (guided by a talking meditation ball) in VR. We will extract some sections of the data when the meditation actually starts. In the first session (__Prestudy__), there is only one part where the subject meditated. In the second session (__Poststudy__), there are two meditation parts (one with a fixed time and the others with varied time). Before each experiment, a baseline (__Prebaseline__) was taken and can use this to normalize our data.\n",
    "\n",
    "## __Prestudy__\n",
    "\n",
    "We have an event marker stream called __EventStream__ (name) and there is one event we are interested in that marks when the meditation starts: __\"Start meditation audio\"__. However, we do not have a marker to mark when the meditating part ends. Fortunately, the same meditation audio is the same in all LSL recordings and each are the same length in time: 530 seconds. We will extract this 530 second section. \n",
    "\n",
    "## __Poststudy__\n",
    "\n",
    "For this second session, we still have a marker stream called __Event Stream__ (name). For the first meditation part, the subject undergoes the same guided meditation as the first session but for only __237 seconds__. This part is guided with the same meditation ball. It uses the same event marker: __\"Start meditation audio\"__. In the second meditation part, the meditation is guided by a \"compassionate tree\", and the time is varied. We still have an event marker to mark when the meditation audio starts: __\"Start second meditation audio\"__. To get the time elapsed in this second meditation part, we look at the video to see how much time elapsed before the end of the meditation audio. We created an Excel Spread sheet (__PostStudy_TreeEvents.xlsx__) that records what the time elapsed in the second meditation audio (for any who did the second session). \n",
    "\n",
    "# Naming Convention\n",
    "\n",
    "Please refer to the __001_ecg_fundamental__ Jupyter Notebook in the same directory as this one is stored. It should provide information on the importance on naming datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd4a268-1c59-4b76-8cde-22a645757674",
   "metadata": {},
   "source": [
    "# __1. Overview__\n",
    "\n",
    "We will process subject data from the VR-CCT project (see above for description). A pre-requisite of this is to go over the __00_lsl_fundamentals__  and the __00_ecg_fundamentals__ Jupyter Notebooks. If you haven't please go back and go over these Notebooks. \n",
    "\n",
    "For the prestudy data, we will find the event marker and create a boolean/logic array that represents time stamps between the onset of the marker and 530 seconds after onset. We can then extract this data. \n",
    "\n",
    "For the poststudy data, we will find the event markers and create boolean arrays. While the first meditation part can be extracted in the same way as the prestudy, the second part requires the additional task of extracting time elapsed after the second marker from the __PostStudy_TreeEvents__ spreadsheet.  \n",
    "\n",
    "This will be an interactive Notebook in which you will need to write code to extract the data. I will provide the answers in a different notebook, but please try to do it yourself. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7788a1b6-939a-46b4-b8da-100c74a24a6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# __2. Prestudy Extraction__\n",
    "\n",
    "## __2.1 Defining Necessary Variables__\n",
    "\n",
    "In the following code block, we provide variables (not all will be used) for you to use in the interactive exercises. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee02cf58-0fd6-4096-9990-d0de0dd1401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory where data is located (change this to where you will store your data)\n",
    "dir_data = 'data'\n",
    "\n",
    "#Directory where xdf is stored: \n",
    "dir_xdf = os.path.join(dir_data,'xdf')\n",
    "\n",
    "#XDF file names\n",
    "file_format = 'vrcct_%s_%s_%s.%s'\n",
    "\n",
    "#Subject Identifiers: \n",
    "subjects = ['p16']\n",
    "\n",
    "#Study Identifier: \n",
    "studies = ['prestudy','poststudy']\n",
    "\n",
    "#Experiment Part: \n",
    "parts = ['condition','prebaseline']\n",
    "\n",
    "#Directories we need to use\n",
    "dir_data = 'data'\n",
    "dir_xdf = os.path.join(dir_data,'xdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83306d65-6f5c-4985-ac5d-adb8fcab9f0a",
   "metadata": {},
   "source": [
    "## __2.2 INTERACTIVE EXERCISE: Loading ECG Data__\n",
    "\n",
    "Load ECG data from the prestudy data using the __pyxdf.load_xdf__ function (for more info use the __?pyxdf.load_xdf__ help information). The ECG is not stored as a dedicated stream, so we need to load the EEG stream and extract ECG.\n",
    "    \n",
    "- Load in the only EEG stream from the prestudy dataset as a variable called __EEG_stream__\n",
    "- ECG is the channel 66 of the EEG stream (remember Python uses zero indexing); extract it and store as a variable called __ECG__. \n",
    "- Extract the timestamps of the ECG/EEG stream and store it as a variable called __ECG_ts__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c43d5a-8d88-4ba2-9c04-45853d6f92b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subject id,study(prestudy),part(condition is meditation)\n",
    "sub = subjects[0]\n",
    "study = studies[0]\n",
    "part = parts[0]\n",
    "\n",
    "#Load in the Prestudy EEG stream and store it as a variable called EEG_stream\n",
    "\n",
    "# Extract ECG from the EEG stream and store it as a variable called EEG (remember what the output is from the last lines)\n",
    "\n",
    "# Extract timestamps for ECG/EEG stream and store it as a variable called ECG_ts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f4093f-c9f3-42fd-a602-9456bad5b563",
   "metadata": {},
   "source": [
    "## __2.3 INTERACTIVE EXERCISE: Loading Marker Stream__\n",
    "\n",
    "Load the marker stream (named __EventStream__) using the __pyxdf.load_xdf__ function. \n",
    "\n",
    "- Load in the __EventStream__ stream frm the prestudy dataset as a variable called __event_stream__\n",
    "- Extract the markers. Note that these are markers are stored as a list of a string. Please use __list comprehension__ to extract them as a list variable called __events__\n",
    "    - Convert this list as a numpy array using the function __np.asarray__. \n",
    "- Extract timestamps for these markers and store it as a variable called __events_ts__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f301408-42cf-4d14-9d68-1198105ab160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the Prestudy Keyboard stream and store it as a variable called event_stream\n",
    "\n",
    "# Extract markers and store as varible named events using list comprehension\n",
    "\n",
    "# Convert list events in last line to a numpy array \n",
    "\n",
    "# Extract timestamps for events and store as variable called events_ts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff8b992-46e9-4259-a69b-9f08ea7bf7dc",
   "metadata": {},
   "source": [
    "## __2.4 Extracting Prestudy Meditation Part__\n",
    "\n",
    "As mentioned earlier, for the prestudy guided meditation ball part, the audio played for a set amount of time (530 seconds). We will find the time when the meditation audio starts (event: __\"Start meditation audio\"__). Then extract our desired section. We will use boolean/logic array to do this. Additionally, we will create a list with the sampling rate (you'll see why we do this in the next section). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dbc3ba-aba9-42e1-80b5-8dee2748d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the time the meditation audio starts\n",
    "t0 = events_ts[events=='Start meditation audio']\n",
    "\n",
    "#Defining time when audio ends\n",
    "tf = t0 + 530 \n",
    "\n",
    "#Boolean array to ECG within these times: \n",
    "ba = (ECG_ts >= t0) & (ECG_ts <= tf)\n",
    "\n",
    "#Extract ECG and timestamps\n",
    "ECG_medball = copy.deepcopy(ECG[ba])\n",
    "ECG_medball_ts = copy.deepcopy(ECG_ts[ba])\n",
    "\n",
    "#Samping rate stored as a list\n",
    "ECG_srate = [EEG_stream[0]['info']['effective_srate']] * len(ECG_medball)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525a6e51-7453-49a1-8c8c-c407058e97c7",
   "metadata": {},
   "source": [
    "## __2.5 Organizing Extracted ECG as a DataFrame__\n",
    "\n",
    "In this section we will finally organize everything into a Pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e6c05-7716-4ae7-9419-f546e4c223f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame: \n",
    "df_prestudy_medBall = pd.DataFrame(\n",
    "    {'timestamp_lsl' : ECG_medball_ts,\n",
    "     'timestamp_norm' : ECG_medball_ts - t0,#normalizing timestamps\n",
    "     'ecg_raw' : ECG_medball,\n",
    "     'srate': ECG_srate}\n",
    ")\n",
    "\n",
    "df_prestudy_medBall.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8693a902-e713-4e73-93ca-8a3db3b716ca",
   "metadata": {},
   "source": [
    "# __3 Post Study Extraction__\n",
    "\n",
    "## __3.1 Helper Function__\n",
    "\n",
    "The meditation ball part of the poststudy can be extracted in the same way as the Prestudy. In this case, the audio only plays for 257 seconds instead of the 530 seconds. The compassion tree part of the poststudy can also be extracted the same, but we have the varied time elapsed after the second. Rather than writing/copying code over and over again, we can write a helper function that we can use for future analysis. Feel free to modify it for your needs. You might even be so inclined to add preprocessing in this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d1cc1-d399-4267-9521-4cb9368f3c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ecg(\n",
    "    pathFile,\n",
    "    channel = 0,\n",
    "    select_streams = None,\n",
    "    event_markers = None\n",
    "):\n",
    "       \n",
    "    \"\"\"\n",
    "    Description: Function to load in xdf files (and other types) and extract ecg data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pathFile: String\n",
    "        Path to xdf recording where ecg is stored\n",
    "    channel: Integer\n",
    "        Channel number where ecg data is stored \n",
    "    select_streams: list of dictionaries (default: None)\n",
    "        The stream you want to load in if there are multiple data streams in the xdf file\n",
    "    event_markers: dictionary (default: None)\n",
    "        The information for what event stream, event marker to start from, and the time \n",
    "        elapsed after the event marker. The dictionary should have the following keys and \n",
    "        values: 'select_streams' should contain a list of dictionaries that is used by \n",
    "        pyxdf.load_xdf to find the event stream, 'start_event' should contain the \n",
    "        marker that you want start the extraction, and 'duration' should contain a \n",
    "        float that is the time elapsed after the start event. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ecgOut: Pandas DataFrame\n",
    "        The DataFrame will have four columns corresponding to timestamps, normalized \n",
    "        timestamps (normalized by the start event), raw ecg data, and sampling rate.\n",
    "\n",
    "    \"\"\"\n",
    "     #Loading in our ECG data: \n",
    "    stream, _ = pyxdf.load_xdf(\n",
    "        pathFile,\n",
    "        select_streams=select_streams\n",
    "    )\n",
    "    \n",
    "    # Extract ECG from the EEG stream and store it as a variable called EEG (remember what the output is from the last lines)\n",
    "    ECG = stream[0]['time_series'][:,int(channel)]\n",
    "\n",
    "    # Extract timestamps for ECG/EEG stream and store it as a variable called ECG_ts\n",
    "    ECG_ts = stream[0]['time_stamps']\n",
    "    \n",
    "    t0 = ECG_ts[0]\n",
    "    \n",
    "    #Extracting only sections of our ECG data: \n",
    "    if not(event_markers is None):\n",
    "        \n",
    "        try: \n",
    "            event_stream,_ = pyxdf.load_xdf(\n",
    "                pathFile,\n",
    "                select_streams=event_markers['select_streams']\n",
    "            )\n",
    "            markers = [m[0] for m in event_stream[0]['time_series']]\n",
    "            markers_t = event_stream[0]['time_stamps']\n",
    "            \n",
    "            i = markers.index(event_markers['start_event'])\n",
    "            t0 = markers_t[i]\n",
    "            tf = t0 + event_markers['duration']\n",
    "            \n",
    "            #Boolean array to ECG within these times: \n",
    "            ba = (ECG_ts >= t0) & (ECG_ts <= tf)\n",
    "\n",
    "            #Extract ECG and timestamps\n",
    "            ECG = copy.deepcopy(ECG[ba])\n",
    "            ECG_ts = copy.deepcopy(ECG_ts[ba])\n",
    "            \n",
    "        except Exception as e: \n",
    "            print('Could not extract Event Markers')\n",
    "            print(e)\n",
    "            return\n",
    "\n",
    "    #Samping rate stored as a list\n",
    "    ECG_srate = [stream[0]['info']['effective_srate']] * len(ECG)\n",
    "    \n",
    "    #OutPut DataFrame: \n",
    "    df_output = pd.DataFrame(\n",
    "        {'timestamp_lsl' : ECG_ts,\n",
    "         'timestamp_norm' : ECG_ts - t0,#normalizing timestamps\n",
    "         'ecg_raw' : ECG,\n",
    "         'srate': ECG_srate}\n",
    "    )\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64d2411-1314-412e-bd0b-4625e10a86d1",
   "metadata": {},
   "source": [
    "## __3.2 Extracting Post Study Meditation Ball with Helper Function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48138fc4-d1af-4613-8aa6-47154474c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#We load/Extract our Poststudy LSL recordings \n",
    "study = studies[1]\n",
    "\n",
    "#Events Dictionary to extract meditation part\n",
    "event_dict = {\n",
    "    'select_streams' : [{'name' : 'EventStream'}],\n",
    "    'start_event' : 'Start meditation audio',\n",
    "    'duration' : 257\n",
    "}\n",
    "\n",
    "#Using our Helper Function\n",
    "df_poststudy_medBall = load_ecg(\n",
    "    os.path.join(dir_xdf,file_format%(sub,study,part,'xdf')),\n",
    "    channel=65,\n",
    "    select_streams=[{'type':'EEG'}],\n",
    "    event_markers = event_dict\n",
    ")\n",
    "\n",
    "df_poststudy_medBall.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ecf38e-4451-4cf6-8093-9e8c5d19993d",
   "metadata": {},
   "source": [
    "## __3.3 INTERACTIVE EXCERCISE: Extracting Poststudy Compassion Tree with Helper Function__\n",
    "\n",
    "To extract this section we need to refer to our __PostStudy_TreeEvents.xlsx__ located in the data directory (dir_data). There are three columns, but only need two of them. The two that we need are the columns __subject__ and __time_elapsed_since_start_audio__. We can load it in as a Pandas DataFrame. We can get the time elapsed using our __sub__ variable. After getting time elapsed, we can use our Helper Function. Perform the following in the next code block. \n",
    "\n",
    "- Load in the PostStudy_TreeEvents spreadsheet as a Pandas DataFrame (call it whatever you want)\n",
    "- Get the time elapsed for our particular subject (call it whatever you want)\n",
    "- Modify the event_dict variable (used in the previous code block) to change the __start_event to \"Start second meditation audio\"__ and __duration to time elapsed in previous step__\n",
    "- Use the Helper Function to extract the Compassion Tree meditation part and call the dataframe as __df_poststudy_compTree__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9836db-d415-4c70-941b-1c339d1692f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in PostStudy_TreeEvents spreadsheet as dataframe\n",
    "\n",
    "#Get time elasped for subject\n",
    "\n",
    "#modify event_dict variable\n",
    "\n",
    "#Extract ECG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ed5f2-6acd-40ca-9f44-4af262df26a8",
   "metadata": {},
   "source": [
    "# __4 Saving All DataFrames__\n",
    "\n",
    "Finally, we can save our data into a folder in our data directory called csv. With these CSVs, we can preprocess them and find R-peaks. Moreover, we can calculate HRV metrics. Look at the 001_ecg_fundamentals Jupyter Notebook to process it and find peaks. Additionally, you can modify the Helper Function to process and find peaks. You may wonder why we have have the subjects, studies, and parts lists. You can iterate over lists with for loops. These for loops can be used to automate our preprocessing pipeline, so I encourage you to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6195c2-cfb7-4e20-8174-a64ccb86e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating our csv directory: \n",
    "dir_csv = os.path.join(dir_data,'csv')\n",
    "\n",
    "if not(os.path.isdir(dir_csv)):\n",
    "    os.mkdir(dir_csv)\n",
    "    print('Created %s'%(dir_csv))\n",
    "    \n",
    "df_prestudy_medBall.to_csv(\n",
    "    os.path.join(dir_csv,file_format%(sub,studies[0],'medBall','csv')),\n",
    "    index=False\n",
    ")\n",
    "df_poststudy_medBall.to_csv(\n",
    "    os.path.join(dir_csv,file_format%(sub,studies[1],'medBall','csv')),\n",
    "    index=False\n",
    ")\n",
    "df_poststudy_compTree.to_csv(\n",
    "    os.path.join(dir_csv,file_format%(sub,studies[1],'compTree','csv')),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17b3f49-8aef-44f9-a7d0-9770f174de1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
